{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo calcular TF-IDF y similitud coseno\n",
    "\n",
    "**Curso**: CC5213 - Recuperación de Información Multimedia  \n",
    "**Profesor**: Juan Manuel Barrios  \n",
    "**Fecha**: 21 de mayo de 2025\n",
    "\n",
    "En ese ejemplo calcularemos la similitud global entre documentos de texto.\n",
    "\n",
    "```\n",
    "pip install scikit-learn pandas\n",
    "```\n",
    "\n",
    "Para cada archivo de texto se calcula un descriptor global (llamado TF-IDF). Esos descriptores se comparan y para cada documento se obtendrá el documento más parecido del mismo conjunto.\n",
    "\n",
    "Para este ejemplo se usarán los documentos en `dataset_ciperchile.21-05-2025.zip`. Este dataset contiene 5.174 documentos obtenidos desde el sitio web https://www.ciperchile.cl/ el día 21 de mayo de 2025.\n",
    "\n",
    "Dataset publicado solo para fines académicos. El derecho de autor de todos los textos pertenece a CIPER Chile https://ciperchile.cl/\n",
    "\n",
    "El archivo `dataset.txt` lista todos los documentos del dataset. Es un archivo de 6 columnas separadas por el caracter tabulador (\\t):\n",
    "  1. Filename: Nombre del archivo en la carpeta dataset\n",
    "  2. Titulo: Título del artículo\n",
    "  3. Por: Autor del artículo\n",
    "  4. Fecha: Fecha de publicación del artículo\n",
    "  5. Tipo_documento: Categoría del documento\n",
    "  6. URL: dirección pública del artículo\n",
    "\n",
    "\n",
    "La carpeta `dataset` están los textos de cada artículo. Cada archivo de nombre `file00000.txt` tienen la siguiente estructura: \n",
    "  * La primera línea es la URL del documento original  \n",
    "  * La segunda línea es el título del documento  \n",
    "  * Desde la tercera línea en adelante es el contenido del artículo\n",
    "\n",
    "Todos los archivos usan codificación UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "class File():\n",
    "    def __init__(self):\n",
    "        self.filename = \"\"\n",
    "        self.titulo = \"\"\n",
    "        self.autor = \"\"\n",
    "        self.fecha = \"\"\n",
    "        self.tipo = \"\"\n",
    "        self.url = \"\"\n",
    "        self.full_text = \"\"\n",
    "\n",
    "    def load_full_text(self, dir_dataset):\n",
    "        file = os.path.join(dir_dataset, self.filename)\n",
    "        with open(file, mode=\"r\", encoding=\"utf8\") as f:\n",
    "            self.full_text = f.read()\n",
    "        # quitar la primera linea (es una url)\n",
    "        self.full_text = self.full_text[self.full_text.find(\"\\n\") + 1 :]\n",
    "  \n",
    "\n",
    "def load_dataset(dir_dataset):\n",
    "    files = list()\n",
    "    header = dict()\n",
    "    file_dataset = os.path.join(dir_dataset, 'dataset.txt')\n",
    "    print(\"leyendo {}...\".format(file_dataset))\n",
    "    with open(file_dataset, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            # leer los nombres de la primera fila \n",
    "            if len(header) == 0:\n",
    "                header = dict((c, i) for i, c in enumerate(fields))\n",
    "                continue\n",
    "            file = File()\n",
    "            file.filename = fields[header[\"Filename\"]]\n",
    "            file.titulo = fields[header[\"Titulo\"]]\n",
    "            file.autor = fields[header[\"Por\"]]\n",
    "            file.fecha = fields[header[\"Fecha\"]]\n",
    "            file.tipo = fields[header[\"Tipo_documento\"]]\n",
    "            file.url = fields[header[\"URL\"]]\n",
    "            files.append(file)\n",
    "    dir_dataset = os.path.join(dir_dataset, 'dataset')\n",
    "    print(\"leyendo textos de {} archivos en {} ...\".format(len(files), dir_dataset))\n",
    "    for file in files:\n",
    "        file.load_full_text(dir_dataset)\n",
    "    return files\n",
    "\n",
    "t1 = time.time()\n",
    "dataset_files = load_dataset('dataset_ciperchile.21-05-2025')\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"leídos {} documentos en {:.1f} segundos\".format(len(dataset_files), t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opcional, restringir los documentos a usar\n",
    "\n",
    "A veces es muy lento usar todos los documentos del dataset o puede faltar memoria.\n",
    "\n",
    "Para reducir la cantidad de documentos a usar cambiar el número a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se podrían usar menos documentos, para que no sea tan lento\n",
    "cantidad_documentos = 5174  #len(dataset_files)\n",
    "\n",
    "dataset_files = dataset_files[0:cantidad_documentos]\n",
    "\n",
    "print(\"Usando {} documentos\".format(len(dataset_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular vocabulario\n",
    "\n",
    "Se usa **TfidfVectorizer** para calcular el vocabulario y crear descriptores.  \n",
    "Ver la documentación en: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#un array con los textos para crear el vocabulario y descriptores\n",
    "textos = list()\n",
    "largo_total = 0\n",
    "for doc in dataset_files:\n",
    "    largo_total += len(doc.full_text)\n",
    "    textos.append(doc.full_text)\n",
    "\n",
    "print(\"Se van a usar {} documentos, con largo total {:.1f} MB\".format(len(textos), largo_total/1024/1024))\n",
    "\n",
    "#calcular el vocabulario: total de palabras a representar\n",
    "t0 = time.time()\n",
    "vectorizer = TfidfVectorizer(lowercase=True,          # por defecto es True \n",
    "                             strip_accents='unicode', # por defecto es None. unicode=eliminar acentos\n",
    "                             sublinear_tf=True,       # por defecto es False. TRUE=usar 1+log(freq) \n",
    "                             use_idf=True,            # por defecto es True\n",
    "                             norm='l2',               # por defecto es l2 (asi el coseno es solo la multiplicacion de valores)\n",
    "                             ngram_range=(1,1),       # por defecto es (1,1). rango de ngramas a usar por ej: (1,1) o (1,2) o (1,3)\n",
    "                             max_df=1.0, # Si una palabra aparece en más que max_df documentos, se ignora (probar con 0.9)\n",
    "                                         #  Si es float -> porcentaje del total de documentos\n",
    "                                         #  Si es int   -> cantidad de documentos\n",
    "                                         #  Notar que es distinto 1.0 (el 100% de los documentos) vs 1 (solo 1 documento)\n",
    "                             min_df=0.0  # Si una palabra aparece en menos que min_df documentos, se ignora (probar con 0.1)\n",
    "                             )           #  También puede ser float o int\n",
    "vectorizer.fit(textos)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"tiempo para crear vocabulario: {:.1f} segs\".format(t1-t0))\n",
    "print(\"vocabulario de {} palabras\".format(len(vectorizer.vocabulary_)))\n",
    "print(\"primeras 10 palabras: \", list(vectorizer.vocabulary_.keys())[0:10])\n",
    "print(\"primeras 10 palabras ordenadas: \", list(sorted(vectorizer.vocabulary_.keys())[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular descriptores\n",
    "\n",
    "Se calcula el descriptor td-idf para cada documento.\n",
    "\n",
    "Notar que `TfidfVectorizer` entrega los descriptores como una matriz de tipo `scipy.sparse._csr.csr_matrix`. Esto implica que ocupa poco espacio en memoria porque solo se guardan los valores distintos de cero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform() entrega el descriptor tf-idf (un vector sparse con los pesos de las palabras)\n",
    "t0 = time.time()\n",
    "descriptores = vectorizer.transform(textos)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"tiempo descriptores: {:.1f} segs\".format(t1-t0))\n",
    "print(\"descriptores es matriz de {}\".format(descriptores.shape))\n",
    "\n",
    "#verificar que los descriptores es una matriz sparse\n",
    "print(\"descriptores tipo {}\".format(type(descriptores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular similares (opción 1: multiplicar matrices)\n",
    "\n",
    "Calcularemos la \"autosimilitud\" que consiste en comparar un dataset consigo mismo. Como los descriptores están normalizados L2, al multiplicar la matriz de descriptores con su transpuesta es lo mismo que calcular la similitud coseno entre todos los descriptores.\n",
    "\n",
    "La matriz de autosimilitud  siempre tendrá 1 en la diagonal porque representa la similitud de un descriptor consigo mismo.\n",
    "\n",
    "Notar que la matriz es tipo `sparse`, por lo que para poder multiplicar con ella será necesario convertirla en matriz densa, llamando a `toarray()`. Dependiendo de la cantidad de términos del vocabulario esto podría fallar por memoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usar la funcion toarray() para convertir los descriptores a una matriz densa\n",
    "#multiplicar las matrices con matmul() para calcular la similitud coseno\n",
    "\n",
    "t0 = time.time()\n",
    "descriptores_denso = descriptores.toarray()\n",
    "auto_similitud = numpy.matmul(descriptores_denso, descriptores_denso.T)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Tiempo comparación todos contra todos: {:.1f} segs\".format(t1-t0))\n",
    "\n",
    "auto_similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imprimir el resultado de similitud coseno\n",
    "\n",
    "Para cada fila se imprime su más cercano (mayor similitud). Para evitar el valor 1 de la diagonal se escribe 0 en la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def imprimir_similares(matriz, min_score):\n",
    "    #obtener el maximo por fila\n",
    "    #primero llenar la diagonal con ceros para que el mas parecido no sea si mismo\n",
    "    numpy.fill_diagonal(matriz, 0)\n",
    "    \n",
    "    filas = []\n",
    "    for i in range(matriz.shape[0]):\n",
    "        #obtener la posicion del maximo por fila\n",
    "        posicion_mayor = numpy.argmax(matriz[i])\n",
    "        #nombres de archivos\n",
    "        nombre_documento = dataset_files[i].filename\n",
    "        nombre_mas_similar = dataset_files[posicion_mayor].filename\n",
    "        similitud = matriz[i, posicion_mayor]\n",
    "        #imprimir documentos con score mayor al mínimo pedido\n",
    "        if similitud >= min_score:\n",
    "            fila = {'id':  i,\n",
    "                    'query':  nombre_documento,\n",
    "                    'documento': nombre_mas_similar,\n",
    "                    'similitud coseno': similitud}\n",
    "            filas.append(fila)\n",
    "    \n",
    "    print(\"documentos con similitud mayor a {}:\".format(min_score))\n",
    "    print()\n",
    "    df = pandas.DataFrame(filas)\n",
    "    print(df.to_string(index=False, justify='center'))\n",
    "\n",
    "imprimir_similares(auto_similitud, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar algunos documentos parecidos\n",
    "\n",
    "Se muestra un documento y su más parecido, para verificar si son similares o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def imprimir_documento(similitudes, i):\n",
    "    # obtener la posicion del maximo por fila\n",
    "    posicion_mayor = numpy.argmax(similitudes[i])\n",
    "    similitud = similitudes[i, posicion_mayor]\n",
    "    # nombres de archivos\n",
    "    nombre_documento = dataset_files[i].filename\n",
    "    url_documento = dataset_files[i].url\n",
    "    texto_documento = dataset_files[i].full_text\n",
    "    # el mas parecido\n",
    "    nombre_similar = dataset_files[posicion_mayor].filename\n",
    "    url_similar = dataset_files[posicion_mayor].url\n",
    "    texto_similar = dataset_files[posicion_mayor].full_text\n",
    "    # mostrar solo el inicio de cada coumento\n",
    "    max_length = 1000\n",
    "    if len(texto_documento) > max_length:\n",
    "        texto_documento = texto_documento[0:max_length]\n",
    "    if len(texto_similar) > max_length:\n",
    "        texto_similar = texto_similar[0:max_length]\n",
    "    # mostrar\n",
    "    print(\"Comparando {} y {} con similitud {:.3f}\".format(nombre_documento, nombre_similar, similitud))\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"  \", nombre_documento, \" -> \", url_documento)\n",
    "    print(texto_documento)\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"  \", nombre_similar, \" -> \", url_similar)\n",
    "    print(texto_similar)\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "# mostrar algun documento\n",
    "id_documento = random.randint(0, auto_similitud.shape[0] + 1) \n",
    "\n",
    "imprimir_documento(auto_similitud, id_documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preguntas:__\n",
    "  * En su opinión, ¿son parecidos los dos documentos mostrados anteriormente?\n",
    "  * ¿Tiene que ver el nivel parecido con el valor de similitud? (probar con varios, por ejemplo con similitud 0.1 vs similitud 0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular similares (opción 2: usar cdist)\n",
    "\n",
    "En vez de multiplicar matrices probaremos la función `cdist()` que ya hemos usado en ejemplos anteriores. Para comparar descriptores configurar la distancia `cosine`, que es igual a (1 - similitud coseno).  \n",
    "Ver métrica 6 en: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "\n",
    "**Notar la diferencia de tiempo comparado con la multiplicación de matrices!!**   \n",
    "Usando `cdist()` para comparar descriptores **demora cerca de una hora**, mientras que la multiplicación de matrices toma algunos segundos. En ambos se obtiene exactamente el mismo resultado.\n",
    "\n",
    "¿A qué se deberá la diferencia en tiempo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "t0 = time.time()\n",
    "descriptores_denso = descriptores.toarray()\n",
    "distancias = distance.cdist(descriptores_denso, descriptores_denso, metric='cosine')\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"tiempo comparacion usando cdist con distancia coseno: {:.1f} segs ({:.1f} mins)\".format(t1-t0,(t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def evaluar_mas_parecido(matriz_distancias, matriz_ideal):\n",
    "    #completar la diagonal con un valor muy grande para el mas cercano no sea si mismo\n",
    "    numpy.fill_diagonal(matriz_distancias, numpy.inf)\n",
    "    #completo la diagonal con cero para que el mas parecido no sea si mismo\n",
    "    numpy.fill_diagonal(matriz_ideal, 0)\n",
    "\n",
    "    #obtener la posicion del mas cercano por fila\n",
    "    posicion_min = numpy.argmin(matriz_distancias, axis=1)\n",
    "    minimo = numpy.amin(matriz_distancias, axis=1)\n",
    "\n",
    "    #posicion del mas similar por fila\n",
    "    posicion_max_ideal = numpy.argmax(matriz_ideal, axis=1)\n",
    "\n",
    "    #imprimir los documentos mas parecidos y su similitud\n",
    "    filas = []\n",
    "    total = matriz_distancias.shape[0]\n",
    "    total_iguales = 0\n",
    "    for i in range(total):\n",
    "        nombre_documento = dataset_files[i].filename\n",
    "        nombre_mas_similar = dataset_files[posicion_min[i]].filename\n",
    "        distancia_menor = minimo[i]\n",
    "        resultado = \"\"\n",
    "        if posicion_min[i] == posicion_max_ideal[i]:\n",
    "            resultado = \"¡igual! :-)\"\n",
    "            total_iguales += 1\n",
    "        else:\n",
    "            nombre_correcto = dataset_files[posicion_max_ideal[i]].filename\n",
    "            resultado = \"¡mal! era {}\".format(nombre_correcto)\n",
    "        fila = {'id':  i,\n",
    "                'query':  nombre_documento,\n",
    "                'documento': nombre_mas_similar,\n",
    "                'distancia coseno': distancia_menor,\n",
    "                'resultado': resultado}\n",
    "        filas.append(fila)\n",
    "\n",
    "    print(\"resultados iguales al original: {} / {} = {:.1f}%\".format(total_iguales, total, total_iguales/total*100))\n",
    "    print()\n",
    "    df = pandas.DataFrame(filas)\n",
    "    print(df.to_string(index=False, justify='center'))\n",
    "\n",
    "evaluar_mas_parecido(distancias, auto_similitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Propuesto\n",
    "\n",
    "Buscar documentos similares para textos de consulta libres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular el documento más similar para los siguientes documentos de consulta.\n",
    "textos_q = [ \"elecciones de alcalde\", \"estudiantes de universidad\"]\n",
    "\n",
    "#1.calcular la matriz de descriptores para textos_q (usar el vocabulario ya calculado)\n",
    "#2.multiplicar los descriptores para obtener la similitud coseno\n",
    "#2.buscar para cada descriptor de textos_q el más similar dentro de la matriz \"descriptores\"\n",
    "#3.imprimir documentos más similares\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
