{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducir dimensionalidad con PCA (Análisis de Componentes Principales)\n",
    "\n",
    "**Curso**: CC5213 - Recuperación de Información Multimedia  \n",
    "**Profesor**: Juan Manuel Barrios  \n",
    "**Fecha**: 21 de junio de 2025  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos interactivos\n",
    "\n",
    "Para los gráficos se usa matplotlib:\n",
    "```\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "Para gráficos interactivos (por ej. hacer zoom):\n",
    "\n",
    "  1. Instalar ipympl:  `pip install ipympl`\n",
    "  2. Reiniciar jupyter \n",
    "  3. Reemplazar `%matplotlib inline` por `%matplotlib widget`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Descomentar esta linea para graficos interactivos\n",
    "## %matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# cargar un conjunto de vectores\n",
    "dataset_q = numpy.load(\"dataset_a_q.npy\")\n",
    "dataset_r = numpy.load(\"dataset_a_r.npy\")\n",
    "\n",
    "print(\"Dataset A: conjunto_Q={} conjunto_R={}\".format(dataset_q.shape, dataset_r.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: centrar los vectores del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios = dataset_r.mean(axis=0)\n",
    "print(\"vector_promedio: {}\".format(promedios))\n",
    "\n",
    "datos_centrados = dataset_r - promedios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: calcular matriz de convarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se usa transpose() para que calcule una matriz de 128x128, bias=False para varianzas divididas por n-1\n",
    "matriz_covarianza = numpy.cov(datos_centrados.transpose(), bias=False)\n",
    "print(\"matriz_covarianza: {}\".format(matriz_covarianza.shape))\n",
    "print(matriz_covarianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: calcular valores y vectores propios de la matriz de covarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = numpy.linalg.eig(matriz_covarianza)\n",
    "print(\"eigenvalues: {}\".format(eigenvalues.shape))\n",
    "print(\"eigenvectors: {}\".format(eigenvectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: ordenar valores propios de mayor a menor (mantener el mismo orden en los vectores propios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices para ordenar\n",
    "indices_menor_a_mayor = eigenvalues.argsort()\n",
    "indices_mayor_a_menor = indices_menor_a_mayor[::-1]\n",
    "\n",
    "# obtener valores y vectores ordenados de mayor a menor\n",
    "eigenvalues = eigenvalues[indices_mayor_a_menor]\n",
    "eigenvectors = eigenvectors[:, indices_mayor_a_menor]\n",
    "\n",
    "print(\"valores propios={}\".format(eigenvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varianza acumulada por los primeros N valores propios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianza_acumulada(dimension):\n",
    "    return numpy.sum(eigenvalues[:dimension]) / numpy.sum(eigenvalues)\n",
    "\n",
    "\n",
    "dimensiones = []\n",
    "varianzas = []\n",
    "for dim in range(0, 129, 4):\n",
    "    pct_varianza = 100 * varianza_acumulada(dim)\n",
    "    pct_dim = 100 * dim / dataset_r.shape[1]\n",
    "    print(\"{}-d\\tdim={:.1f}%\\tvar={:.1f}%\\t\".format(dim, pct_dim, pct_varianza))\n",
    "    dimensiones.append(pct_dim)\n",
    "    varianzas.append(pct_varianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    dimensiones,\n",
    "    varianzas,\n",
    "    label=\"varianza\",\n",
    "    color=\"b\",\n",
    "    linestyle=\"-\",\n",
    "    marker=\"o\",\n",
    "    markerfacecolor=\"g\",\n",
    "    markersize=6,\n",
    ")\n",
    "plt.title(\"Varianza total al considerar un % de dimensiones\")\n",
    "plt.xlabel(\"dimensión %\")\n",
    "plt.ylabel(\"varianza acumulada %\")\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico anterior se ve que la mayor cantidad de varianza se encuentra en las primeras componentes principales:   \n",
    "El 50% de la varianza se encuentra en las primeras 8 coordenadas.  \n",
    "El 75% de la varianza se encuentra en las primeras 24 coordenadas.  \n",
    "El 95% de la varianza se encuentra en las primeras 68 coordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: matriz de transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unir primeros N vectores propios\n",
    "def transformar(dataset, new_dims):\n",
    "    centrado = dataset - promedios\n",
    "    transformacion = eigenvectors[:, :new_dims]\n",
    "    transformado = centrado.dot(transformacion)\n",
    "    return transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: transformar matriz de descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINALES Q={} R={}\".format(dataset_q.shape, dataset_r.shape))\n",
    "\n",
    "r_reducido = transformar(dataset_r, 10)\n",
    "q_reducido = transformar(dataset_q, 10)\n",
    "\n",
    "print(\"REDUCIDOS  Q={}  R={}\".format(q_reducido.shape, r_reducido.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación: los vectores transformados no tienen covarianzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r_reducido: {}\".format(r_reducido.shape))\n",
    "\n",
    "r_reducido_centrado = r_reducido - r_reducido.mean(axis=0)\n",
    "print(\"r_reducido_centrado: {}\".format(r_reducido_centrado.shape))\n",
    "\n",
    "r_reducido_covarianza = numpy.cov(r_reducido_centrado.transpose(), bias=False)\n",
    "print(\"matriz_covarianza: {}\".format(r_reducido_covarianza.shape))\n",
    "\n",
    "# las covarianzas debieran ser cercanas a 0\n",
    "print()\n",
    "print(\"covarianzas={}\".format(r_reducido_covarianza[0][1]))\n",
    "print(\"covarianzas={}\".format(r_reducido_covarianza[2][3]))\n",
    "print(\"covarianzas={}\".format(r_reducido_covarianza[4][3]))\n",
    "print()\n",
    "print(\"varianzas={}\".format(r_reducido_covarianza[0][0]))\n",
    "print(\"varianzas={}\".format(r_reducido_covarianza[1][1]))\n",
    "print(\"varianzas={}\".format(r_reducido_covarianza[2][2]))\n",
    "print()\n",
    "print(\"matriz de covarianza={}\".format(r_reducido_covarianza))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio: Transformar otro conjunto de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar con otro dataset\n",
    "dataset_q = numpy.load(\"dataset_b_q.npy\")\n",
    "dataset_r = numpy.load(\"dataset_b_r.npy\")\n",
    "\n",
    "print(\"Dataset B: conjunto_Q={} conjunto_R={}\".format(dataset_q.shape, dataset_r.shape))\n",
    "\n",
    "# probar de nuevo el resultado con este dataset y verificar si entregs los mismos valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Comparar las varianzas acumuladas de este dataset y el anterior. **¿Se distribuyen igual los porcentajes de varianza entre los datasets A y B?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
