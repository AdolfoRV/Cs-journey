{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsquedas aproximadas con LSH (Locality Sensitive Hashing)\n",
    "\n",
    "**Curso**: CC5213 - Recuperación de Información Multimedia  \n",
    "**Profesor**: Juan Manuel Barrios  \n",
    "**Fecha**: 21 de junio de 2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar NearPy con:\n",
    "\n",
    "```\n",
    "  conda install nearpy\n",
    "```\n",
    "\n",
    "La documentación de NearPy está disponible en https://github.com/pixelogik/NearPy\n",
    "\n",
    "Si se está usando anaconda, instalar con  `conda install -c conda-forge nearpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero cargar algunas funciones auxiliares\n",
    "import numpy\n",
    "import time\n",
    "import pyflann\n",
    "\n",
    "\n",
    "# calcular la calidad de la respuesta contra el resultado \"ideal\" dado por el linear scan\n",
    "class Experimento:\n",
    "    def __init__(self, nombre, archivo_dataset_q, archivo_dataset_r):\n",
    "        self.nombre = nombre\n",
    "        # cargar conjuntos de vectores Q y R\n",
    "        self.dataset_q = numpy.load(archivo_dataset_q)\n",
    "        self.dataset_r = numpy.load(archivo_dataset_r)\n",
    "        print(\n",
    "            \"{}: conjunto_Q={} conjunto_R={}\".format(\n",
    "                nombre, self.dataset_q.shape, self.dataset_r.shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def calcular_linear_scan(self):\n",
    "        # crear un objeto flann\n",
    "        flann = pyflann.FLANN()\n",
    "        # construir el indice para linear scan\n",
    "        flann.build_index(self.dataset_r, algorithm=\"linear\")\n",
    "        # ejecutar el linear scan, se usa un solo core, debiera demorar unos 25 a 35 segundos\n",
    "        t0 = time.time()\n",
    "        nns, dists = flann.nn_index(experimentoA.dataset_q, num_neighbors=1, cores=1)\n",
    "        # se guarda el objeto encontrado, no se guarda la distancia porque LSH no la calcula\n",
    "        self.gt_nns = nns\n",
    "        self.gt_tiempo = time.time() - t0\n",
    "        self.correctas = 0\n",
    "        self.incorrectas = 0\n",
    "        self.tiempo = 0\n",
    "        self.precision = 0\n",
    "        self.eficiencia = 0\n",
    "        print(\n",
    "            \"{}: Linear Scan toma {:.1f} segundos\".format(self.nombre, self.gt_tiempo)\n",
    "        )\n",
    "\n",
    "    def evaluar_busqueda(self, nombre_indice, nns, segundos):\n",
    "        self.correctas = 0\n",
    "        self.incorrectas = 0\n",
    "        for i in range(len(self.gt_nns)):\n",
    "            # es correcta si encontró el mismo elemento que el linear scan\n",
    "            if nns[i] == self.gt_nns[i]:\n",
    "                self.correctas += 1\n",
    "            else:\n",
    "                self.incorrectas += 1\n",
    "        self.tiempo = segundos\n",
    "        self.precision = self.correctas / (self.correctas + self.incorrectas)\n",
    "        self.eficiencia = self.tiempo / self.gt_tiempo\n",
    "        print(\n",
    "            \"{:<38}: correctas={:>4} incorrectas={:>4} precision={:>6.1%} tiempo={:>4.1f} seg. ({:>5.1%} de LS)\".format(\n",
    "                nombre_indice,\n",
    "                self.correctas,\n",
    "                self.incorrectas,\n",
    "                self.precision,\n",
    "                self.tiempo,\n",
    "                self.eficiencia,\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "experimentoA = Experimento(\"DATASET_A\", \"dataset_a_q.npy\", \"dataset_a_r.npy\")\n",
    "experimentoA.calcular_linear_scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir índice LSH y resolver búsquedas kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nearpy\n",
    "\n",
    "\n",
    "def crear_indice_lsh(dataset_r, cantidad_hashes, projection_count, bin_width):\n",
    "    t0 = time.time()\n",
    "    # definir las funciones de hash\n",
    "    lsh_funciones = []\n",
    "    for i in range(cantidad_hashes):\n",
    "        num = len(lsh_funciones)\n",
    "        nombre = \"hash_\" + str(num)\n",
    "        # crear la funcion de hash\n",
    "        func_hash = nearpy.hashes.RandomDiscretizedProjections(\n",
    "            hash_name=nombre,\n",
    "            projection_count=projection_count,\n",
    "            bin_width=bin_width,\n",
    "            rand_seed=num,\n",
    "        )\n",
    "        # agregarla a la lista\n",
    "        lsh_funciones.append(func_hash)\n",
    "    # crear estructura\n",
    "    lsh_engine = nearpy.Engine(\n",
    "        dim=dataset_r.shape[1],\n",
    "        lshashes=lsh_funciones,\n",
    "        distance=nearpy.distances.EuclideanDistance(),\n",
    "        vector_filters=[nearpy.filters.nearestfilter.NearestFilter(1)],\n",
    "    )\n",
    "    # construir el indice\n",
    "    for i in range(dataset_r.shape[0]):\n",
    "        lsh_engine.store_vector(dataset_r[i], i)\n",
    "    segundos = time.time() - t0\n",
    "    return lsh_engine, segundos\n",
    "\n",
    "\n",
    "def busqueda_NN_lsh(dataset_q, lsh_engine):\n",
    "    t0 = time.time()\n",
    "    nn_results = []\n",
    "    for i in range(dataset_q.shape[0]):\n",
    "        results = lsh_engine.neighbours(dataset_q[i])\n",
    "        id_vector_nn = -1\n",
    "        if len(results) > 0:\n",
    "            nn_data = results[0]\n",
    "            id_vector_nn = nn_data[1]\n",
    "        nn_results.append(id_vector_nn)\n",
    "    segundos = time.time() - t0\n",
    "    return nn_results, segundos\n",
    "\n",
    "\n",
    "def indexar_y_evaluar_lsh(experimento, cantidad_hashes, projection_count, bin_width):\n",
    "    nombre_indice = (\n",
    "        f\"LSH hashes={cantidad_hashes} proyecciones={projection_count} bins={bin_width}\"\n",
    "    )\n",
    "    print(\"{}: construyendo indice {}\".format(experimento.nombre, nombre_indice))\n",
    "    lsh_engine, segundos = crear_indice_lsh(\n",
    "        experimento.dataset_r, cantidad_hashes, projection_count, bin_width\n",
    "    )\n",
    "    print(\"    tiempo construccion: {:.1f} segundos\".format(segundos))\n",
    "    nns, segundos = busqueda_NN_lsh(experimento.dataset_q, lsh_engine)\n",
    "    experimento.evaluar_busqueda(nombre_indice, nns, segundos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar una función LSH simple en ambos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_hashes = 3\n",
    "projection_count = 10\n",
    "bin_width = 10\n",
    "\n",
    "indexar_y_evaluar_lsh(experimentoA, cantidad_hashes, projection_count, bin_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando con distintos parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for cantidad_hashes in [5, 10]:\n",
    "    for projection_count in [10, 15]:\n",
    "        for bin_width in [300, 400, 500, 600]:\n",
    "            cont += 1\n",
    "            print()\n",
    "            print(\"caso \" + str(cont))\n",
    "            indexar_y_evaluar_lsh(\n",
    "                experimentoA, cantidad_hashes, projection_count, bin_width\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las mejores configuraciones (obtenidas en mi computador, puede variar) son:\n",
    "```\n",
    "LSH hashes=5  proyecciones=10 bins=600: correctas=3415 incorrectas=1585 precision=68.3%\ttiempo=8.41\tseg. (27.0% del tiempo de Linear Scan)\n",
    "LSH hashes=10 proyecciones=10 bins=500: correctas=3502 incorrectas=1498 precision=70.0%\ttiempo=5.87\tseg. (18.8% del tiempo de Linear Scan)\n",
    "LSH hashes=10 proyecciones=10 bins=600: correctas=3849 incorrectas=1151 precision=77.0%\ttiempo=13.22 seg. (42.4% del tiempo de Linear Scan)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Comparar con performance obtenida en Dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentoB = Experimento(\"DATASET_B\", \"dataset_b_q.npy\", \"dataset_b_r.npy\")\n",
    "# experimentoB.calcular_linear_scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con LSH se pueden resolver las búsquedas más rápido que el linear scan pagando un costo en la precisión.\n",
    "\n",
    "**¿Cómo es la relación precision vs eficiencia comparado con los árboles? (ver anexos anteriores)**\n",
    "\n",
    "Notar que un índice LSH, el nivel de aproximación de la búsqueda (esto es, qué tan rápido va a ir vs qué calidad de respuesta) se decide en la etapa offline (durante la construcción del índice).   \n",
    "Si se desea mejorar la calidad de respuesta es necesario construir un nuevo índice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
