{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsquedas aproximadas con PCA (Análisis de Componentes Principales)\n",
    "\n",
    "**Curso**: CC5213 - Recuperación de Información Multimedia  \n",
    "**Profesor**: Juan Manuel Barrios  \n",
    "**Fecha**: 21 de junio de 2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos interactivos\n",
    "\n",
    "Para los gráficos se usa matplotlib:\n",
    "```\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "Para gráficos interactivos (por ej. hacer zoom):\n",
    "\n",
    "  1. Instalar ipympl:  `pip install ipympl`\n",
    "  2. Reiniciar jupyter \n",
    "  3. Reemplazar `%matplotlib inline` por `%matplotlib widget`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Descomentar esta linea para graficos interactivos\n",
    "## %matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, nombre, archivo_q, archivo_r):\n",
    "        self.nombre = nombre\n",
    "        self.q = numpy.load(archivo_q)\n",
    "        self.r = numpy.load(archivo_r)\n",
    "        print(\"Dataset {}: Q={} R={}\".format(self.nombre, self.q.shape, self.r.shape))\n",
    "\n",
    "\n",
    "datasetA = Dataset(\"DATASET_A\", \"dataset_a_q.npy\", \"dataset_a_r.npy\")\n",
    "datasetB = Dataset(\"DATASET_B\", \"dataset_b_q.npy\", \"dataset_b_r.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objeto que hace la comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyflann\n",
    "\n",
    "\n",
    "class EvaluarPCA:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.flann = pyflann.FLANN()\n",
    "        self.dimensiones = []\n",
    "        self.varianzas = []\n",
    "        self.precisiones = []\n",
    "        self.eficiencias = []\n",
    "\n",
    "    def linear_scan(self):\n",
    "        print(\n",
    "            \"{} linear scan de Q={}xR={}\".format(\n",
    "                self.dataset.nombre, self.dataset.q.shape, self.dataset.r.shape\n",
    "            )\n",
    "        )\n",
    "        self.flann.build_index(self.dataset.r, algorithm=\"linear\")\n",
    "        t0 = time.time()\n",
    "        self.gt_nns, self.gt_dists = self.flann.nn_index(\n",
    "            self.dataset.q, num_neighbors=1, cores=2\n",
    "        )\n",
    "        self.gt_segundos = time.time() - t0\n",
    "        print(\n",
    "            \"{} linear scan = {:.1f} segundos\".format(\n",
    "                self.dataset.nombre, self.gt_segundos\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def calcular_PCA(self):\n",
    "        self.promedios = self.dataset.r.mean(axis=0)\n",
    "        datos_centrados = self.dataset.r - self.promedios\n",
    "        # matriz de covarianza\n",
    "        matriz_covarianza = numpy.cov(datos_centrados.transpose(), bias=True)\n",
    "        # valores y vectores propios de la matriz de covarianza\n",
    "        eigenvalues, eigenvectors = numpy.linalg.eig(matriz_covarianza)\n",
    "        # indices ordenados\n",
    "        indices_menor_a_mayor = eigenvalues.argsort()\n",
    "        indices_mayor_a_menor = indices_menor_a_mayor[::-1]\n",
    "        # guardar valores y vectores propios de mayor a menor\n",
    "        self.eigenvalues = eigenvalues[indices_mayor_a_menor]\n",
    "        self.eigenvectors = eigenvectors[:, indices_mayor_a_menor]\n",
    "\n",
    "    def evaluar_busqueda(self, nns, dists, tiempo):\n",
    "        correctas = 0\n",
    "        incorrectas = 0\n",
    "        for i in range(len(self.gt_nns)):\n",
    "            if nns[i] == self.gt_nns[i]:\n",
    "                correctas += 1\n",
    "            else:\n",
    "                incorrectas += 1\n",
    "        precision = correctas / (correctas + incorrectas)\n",
    "        eficiencia = tiempo / self.gt_segundos\n",
    "        return precision, eficiencia\n",
    "\n",
    "    def reducir_y_buscar(self, new_dims):\n",
    "        varianza_retenida = numpy.sum(self.eigenvalues[:new_dims]) / numpy.sum(\n",
    "            self.eigenvalues\n",
    "        )\n",
    "        dimension = new_dims / self.dataset.r.shape[1]\n",
    "        # reducir R (parte de la fase offline)\n",
    "        r_centrado = self.dataset.r - self.promedios\n",
    "        transformacion = self.eigenvectors[:, :new_dims]\n",
    "        r_newdim = r_centrado.dot(transformacion)\n",
    "        # reducir Q (fase online)\n",
    "        t0 = time.time()\n",
    "        q_centrado = self.dataset.q - self.promedios\n",
    "        q_newdim = q_centrado.dot(transformacion)\n",
    "        # buscar entre Q y R reducidos con linear scan\n",
    "        self.flann.build_index(r_newdim, algorithm=\"linear\")\n",
    "        nns_search, dists_search = self.flann.nn_index(\n",
    "            q_newdim, num_neighbors=1, cores=2\n",
    "        )\n",
    "        segundos = time.time() - t0\n",
    "        # medir resultado de la busqueda\n",
    "        precision, eficiencia = self.evaluar_busqueda(\n",
    "            nns_search, dists_search, segundos\n",
    "        )\n",
    "        # guardar resultados\n",
    "        print(\n",
    "            \"{} PCA-{:<3} dim={:>6.1%}  var={:>6.1%}  precision={:>6.1%}  tiempo={:>6.1%} ({:4.1f} seg.)\".format(\n",
    "                self.dataset.nombre,\n",
    "                new_dims,\n",
    "                dimension,\n",
    "                varianza_retenida,\n",
    "                precision,\n",
    "                eficiencia,\n",
    "                segundos,\n",
    "            )\n",
    "        )\n",
    "        self.dimensiones.append(dimension)\n",
    "        self.varianzas.append(varianza_retenida)\n",
    "        self.precisiones.append(precision)\n",
    "        self.eficiencias.append(eficiencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento en ambos datasets (Dataset_A y Dataset_B)\n",
    "\n",
    "El experimento consiste en:\n",
    "\n",
    "  1. Calcular vecinos más cercanos con linear scan (linea base)\n",
    "  2. Reducir dimensiones\n",
    "  3. Calcular vecinos más cercanos en el espacio reducido\n",
    "  4. Comparar los vecinos encontrados con los reales\n",
    "  5. Calcular el % de respuestas correctas y el tiempo que tomó la búsqueda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev1 = EvaluarPCA(datasetA)\n",
    "ev1.linear_scan()\n",
    "ev1.calcular_PCA()\n",
    "for dims in 2, 4, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128:\n",
    "    ev1.reducir_y_buscar(dims)\n",
    "\n",
    "print()\n",
    "\n",
    "ev2 = EvaluarPCA(datasetB)\n",
    "ev2.linear_scan()\n",
    "ev2.calcular_PCA()\n",
    "for dims in 2, 4, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128:\n",
    "    ev2.reducir_y_buscar(dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    ev1.precisiones,\n",
    "    ev1.eficiencias,\n",
    "    label=ev1.dataset.nombre,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"o\",\n",
    "    markerfacecolor=\"c\",\n",
    "    markersize=8,\n",
    ")\n",
    "plt.plot(\n",
    "    ev2.precisiones,\n",
    "    ev2.eficiencias,\n",
    "    label=ev2.dataset.nombre,\n",
    "    color=\"g\",\n",
    "    linestyle=\"-.\",\n",
    "    marker=\"^\",\n",
    "    markerfacecolor=\"m\",\n",
    "    markersize=8,\n",
    ")\n",
    "plt.xlabel(\"Precisión NN [comparado con LS]\")\n",
    "plt.ylabel(\"Tiempos [comparado con LS]\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi computador, el linear scan en cada conjunto toma 9.2 segundos\n",
    "\n",
    "Cuando los conjuntos se reducen a 32 dimensiones, el tiempo de búsqueda es cercano a la mitad del tiempo original. \n",
    "\n",
    "```\n",
    "DATASET_A PCA-32  dim= 25.0%  var= 82.0%  precision= 64.1%  tiempo= 49.3% ( 4.6 seg.)\n",
    "DATASET_B PCA-32  dim= 25.0%  var= 88.1%  precision= 54.8%  tiempo= 47.4% ( 4.4 seg.)\n",
    "```\n",
    "\n",
    "La calidad de respuesta obtenida es que entre 55% a 65% de vecinos más cercanos correctos.\n",
    "\n",
    "\n",
    "**¿Cómo es la relación precision vs eficiencia comparado con los árboles y con LSH? (ver anexos anteriores)**\n",
    "\n",
    "\n",
    "\n",
    "**Pregunta:** ¿Sería posible estimar la calidad de la respuesta de la búsqueda aproximada sin tener que realizar el linear scan? Notar que en DATASET_B para 32 dimensiones la varianza retenida en la proyección es mayor que en DATASET_A, pero la calidad de respuesta es peor (menos NN correctos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
